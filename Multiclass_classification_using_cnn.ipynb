{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shubham62025865/project/blob/main/Multiclass_classification_using_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4QiYgPA0Rpuq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PROJECT OF *CNN*"
      ],
      "metadata": {
        "id": "XvdtthZURsuK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-Y7ow9D9SFMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ],
      "metadata": {
        "id": "lYI63Z5qhFnc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbWYERUgg5Ne",
        "outputId": "e868ca5e-1e67-4043-dc5c-40be98c2d5d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Libraries Imported Successfully\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import cv2\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import InputLayer, Conv2D, MaxPool2D,Flatten, GlobalMaxPool2D, Dense\n",
        "\n",
        "print(\"✅ Libraries Imported Successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare Data"
      ],
      "metadata": {
        "id": "e_fUxNA4ickw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "mS_pgKOAimzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# unzip data folder\n",
        "\n",
        "! unzip \"/content/drive/MyDrive/learn&build/Machine_learning_classes/Deep Learning/cnn/food_10.zip\""
      ],
      "metadata": {
        "id": "wxyHSi32iVDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(\"/content/food_10\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7gOfyzVkSk6",
        "outputId": "bc9af951-ad6b-486e-c16d-b3dbbd8c8a5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ice_cream',\n",
              " 'french_fries',\n",
              " 'apple_pie',\n",
              " 'dumplings',\n",
              " 'donuts',\n",
              " 'garlic_bread',\n",
              " 'cup_cakes',\n",
              " 'waffles',\n",
              " 'chocolate_cake',\n",
              " 'samosa']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename = os.listdir(os.path.join(\"/content/food_10\", \"donuts\"))\n",
        "len(filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sD_Hh6m1km2s",
        "outputId": "04d99883-f9d4-4bd4-cd1f-1569ab35d09c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# finding number of images in each food category\n",
        "for folder in os.listdir(\"/content/food_10\"):\n",
        "  file_name = os.listdir(os.path.join(\"/content/food_10\", folder))\n",
        "  print(f\"{folder} containg {len(file_name)} images\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpBsWhQci48I",
        "outputId": "968d5161-21ad-40b1-c6df-0802d850eaa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ice_cream containg 1000 images\n",
            "french_fries containg 1000 images\n",
            "apple_pie containg 1000 images\n",
            "dumplings containg 1000 images\n",
            "donuts containg 1000 images\n",
            "garlic_bread containg 1000 images\n",
            "cup_cakes containg 1000 images\n",
            "waffles containg 1000 images\n",
            "chocolate_cake containg 1000 images\n",
            "samosa containg 1000 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.path.split(\"/content/food_10/chocolate_cake\")[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "wBp5Sxa-nkBX",
        "outputId": "6b658361-e526-460d-f477-a9fd0653f22a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'chocolate_cake'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split data in train test\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "paths = {\n",
        "    \"data_path\" : os.path.join(os.getcwd(),\"data\"),\n",
        "    \"train_path\" : os.path.join(os.getcwd(),\"data\", \"train\"),\n",
        "    \"test_path\" : os.path.join(os.getcwd(),\"data\",\"test\")\n",
        "}\n",
        "\n",
        "def image_data_prep(img_dir, test_ratio):\n",
        "\n",
        "  '''\n",
        "  Takes image directory address as input\n",
        "  img_dir: Category image folder address\n",
        "  test_ratio : Ratio of total files you want in test must be in float (0,1)\n",
        "  '''\n",
        "\n",
        "  image_names = os.listdir(img_dir)\n",
        "  food_cat = os.path.split(img_dir)[-1]\n",
        "\n",
        "  #shuffle image_names\n",
        "  random.seed(42)\n",
        "  random.shuffle(image_names)\n",
        "\n",
        "  num_test = round(len(image_names) * test_ratio)\n",
        "\n",
        "  print(f'number of {food_cat} images in test folder {num_test}' )\n",
        "\n",
        "  test_img = image_names[:num_test]\n",
        "  train_img = image_names[num_test:]\n",
        "\n",
        "  if not(os.path.exists(paths[\"data_path\"])):\n",
        "    os.mkdir(paths[\"data_path\"])\n",
        "\n",
        "  if not(os.path.exists(paths[\"train_path\"])):\n",
        "    os.mkdir(paths[\"train_path\"])\n",
        "\n",
        "  if not(os.path.exists(paths[\"test_path\"])):\n",
        "    os.mkdir(paths[\"test_path\"])\n",
        "\n",
        "  food_cat_train_path = os.path.join(paths[\"train_path\"], food_cat)\n",
        "  food_cat_test_path = os.path.join(paths[\"test_path\"], food_cat)\n",
        "\n",
        "  os.mkdir(food_cat_train_path)\n",
        "  os.mkdir(food_cat_test_path)\n",
        "\n",
        "  for img in test_img:\n",
        "    src = os.path.join(img_dir, img)\n",
        "    dst = food_cat_test_path\n",
        "    shutil.move(src, dst)\n",
        "\n",
        "  for img in train_img:\n",
        "    src = os.path.join(img_dir, img)\n",
        "    dst = food_cat_train_path\n",
        "    shutil.move(src, dst)"
      ],
      "metadata": {
        "id": "tppSiaRBloIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for folder in os.listdir(\"/content/food_10\"):\n",
        "  img_dir = os.path.join(\"/content/food_10\", folder)\n",
        "  image_data_prep(img_dir, test_ratio = 0.25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYSamps9mNtl",
        "outputId": "4596dceb-dfe8-4f0e-b902-a101ba5d1c82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of ice_cream images in test folder 250\n",
            "number of french_fries images in test folder 250\n",
            "number of apple_pie images in test folder 250\n",
            "number of dumplings images in test folder 250\n",
            "number of donuts images in test folder 250\n",
            "number of garlic_bread images in test folder 250\n",
            "number of cup_cakes images in test folder 250\n",
            "number of waffles images in test folder 250\n",
            "number of chocolate_cake images in test folder 250\n",
            "number of samosa images in test folder 250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess and load data"
      ],
      "metadata": {
        "id": "Rk75ugdNq78k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1.0/255)\n",
        "test_datagen = ImageDataGenerator(rescale = 1.0/255)\n",
        "\n",
        "train_data = train_datagen.flow_from_directory(\n",
        "    paths[\"train_path\"],\n",
        "    target_size = (400,400),\n",
        "    batch_size = 32,\n",
        "    class_mode = \"categorical\",\n",
        "    seed = 42\n",
        ")\n",
        "\n",
        "test_data = test_datagen.flow_from_directory(\n",
        "    paths[\"test_path\"],\n",
        "    target_size = (400,400),\n",
        "    batch_size = 32,\n",
        "    class_mode = \"categorical\",\n",
        "    seed = 42\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwGHUH9uqsCR",
        "outputId": "21a15213-3fe1-465c-cf40-51476dd137e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7500 images belonging to 10 classes.\n",
            "Found 2500 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch = train_data.next()"
      ],
      "metadata": {
        "id": "e89mK6PlsINY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch[0].shape, batch[1].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqA7r1gysTVN",
        "outputId": "64c04cf1-cf3d-4121-aa61-4bf6c127dd83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((32, 400, 400, 3), (32, 10))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch[0][0]"
      ],
      "metadata": {
        "id": "fKDOoVQ0stfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch[1][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJ8dyb6Qtbl8",
        "outputId": "8117178d-f8d4-4011-9efb-a7b8af4757d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    InputLayer(input_shape = (400,400,3)),\n",
        "    Conv2D(filters = 32,\n",
        "           kernel_size = (3,3),\n",
        "           strides = (1,1),\n",
        "           padding = \"valid\",\n",
        "           activation = \"relu\"\n",
        "           ),\n",
        "\n",
        "    Conv2D(filters = 32,\n",
        "           kernel_size = (3,3),\n",
        "           strides = (1,1),\n",
        "           padding = \"valid\",\n",
        "           activation = \"relu\"\n",
        "           ),\n",
        "    MaxPool2D(),\n",
        "\n",
        "    Conv2D(filters = 16,\n",
        "           kernel_size = (3,3),\n",
        "           strides = (1,1),\n",
        "           padding = \"valid\",\n",
        "           activation = \"relu\"\n",
        "           ),\n",
        "\n",
        "    Conv2D(filters = 16,\n",
        "           kernel_size = (3,3),\n",
        "           strides = (1,1),\n",
        "           padding = \"valid\",\n",
        "           activation = \"relu\"\n",
        "           ),\n",
        "    MaxPool2D(),\n",
        "\n",
        "    GlobalMaxPool2D(),\n",
        "    Dense(50, activation = \"relu\"),\n",
        "    Dense(10, activation = \"softmax\")\n",
        "\n",
        "])"
      ],
      "metadata": {
        "id": "Ese3FV5iths3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    loss = \"categorical_crossentropy\",\n",
        "    optimizer = \"adam\",\n",
        "    metrics = [\"accuracy\"]\n",
        ")\n",
        "\n",
        "result = model.fit(train_data, epochs = 5, validation_data = test_data)"
      ],
      "metadata": {
        "id": "i2coHALmt8vm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "tensorflow hub - https://tfhub.dev/\n",
        "\n",
        "copying feature vector url of efficientnet_v2 - https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_s/feature_vector/2"
      ],
      "metadata": {
        "id": "VUU6NEgGwBwt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "\n",
        "model_layer = hub.KerasLayer(\"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_s/feature_vector/2\")\n",
        "\n",
        "model_2 = tf.keras.models.Sequential([\n",
        "    InputLayer(input_shape = (400,400,3)),\n",
        "    model_layer,\n",
        "    Dense(10, activation = \"softmax\")\n",
        "])\n",
        "\n",
        "model_2.compile(loss = \"categorical_crossentropy\",\n",
        "    optimizer = \"adam\",\n",
        "    metrics = [\"accuracy\"]\n",
        ")\n",
        "\n",
        "result = model_2.fit(train_data, epochs = 5, validation_data = test_data)"
      ],
      "metadata": {
        "id": "zRKsOodWuhnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUNyuMb1zC2k",
        "outputId": "6c2bd864-8a74-408b-db57-26fee35569c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " keras_layer_2 (KerasLayer)  (None, 1280)              20331360  \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 10)                12810     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20344170 (77.61 MB)\n",
            "Trainable params: 12810 (50.04 KB)\n",
            "Non-trainable params: 20331360 (77.56 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NEq6R-qQ0H-0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}